
@misc{hamalainen_video_2022,
	title = {Video {Games} as a {Corpus}: {Sentiment} {Analysis} using {Fallout} {New} {Vegas} {Dialog}},
	shorttitle = {Video {Games} as a {Corpus}},
	url = {https://arxiv.org/abs/2212.02168v1},
	abstract = {We present a method for extracting a multilingual sentiment annotated dialog data set from Fallout New Vegas. The game developers have preannotated every line of dialog in the game in one of the 8 different sentiments: {\textbackslash}textit\{anger, disgust, fear, happy, neutral, pained, sad \} and {\textbackslash}textit\{surprised\}. The game has been translated into English, Spanish, German, French and Italian. We conduct experiments on multilingual, multilabel sentiment analysis on the extracted data set using multilingual BERT, XLMRoBERTa and language specific BERT models. In our experiments, multilingual BERT outperformed XLMRoBERTa for most of the languages, also language specific models were slightly better than multilingual BERT for most of the languages. The best overall accuracy was 54 percent and it was achieved by using multilingual BERT on Spanish data. The extracted data set presents a challenging task for sentiment analysis. We have released the data, including the testing and training splits, openly on Zenodo. The data set has been shuffled for copyright reasons.},
	language = {en},
	urldate = {2023-04-02},
	journal = {arXiv.org},
	author = {Hämäläinen, Mika and Alnajjar, Khalid and Poibeau, Thierry},
	month = dec,
	year = {2022},
	file = {Full Text PDF:C\:\\Users\\kiera\\Zotero\\storage\\CQHCHJQG\\Hämäläinen et al. - 2022 - Video Games as a Corpus Sentiment Analysis using .pdf:application/pdf},
}

@inproceedings{maghilnan_sentiment_2017,
	title = {Sentiment analysis on speaker specific speech data},
	doi = {10.1109/I2C2.2017.8321795},
	abstract = {Sentiment analysis has evolved over past few decades, most of the work in it revolved around textual sentiment analysis with text mining techniques. But audio sentiment analysis is still in a nascent stage in the research community. In this proposed research, we perform sentiment analysis on speaker discriminated speech transcripts to detect the emotions of the individual speakers involved in the conversation. We analyzed different techniques to perform speaker discrimination and sentiment analysis to find efficient algorithms to perform this task.},
	booktitle = {2017 {International} {Conference} on {Intelligent} {Computing} and {Control} ({I2C2})},
	author = {Maghilnan, S and Kumar, M Rajesh},
	month = jun,
	year = {2017},
	keywords = {DTW, Feature extraction, Mel frequency cepstral coefficient, MFCC, Sentiment analysis, Sentiment Analysis, Speaker recognition, Speaker Recognition, Speech, Speech recognition, Speech Recognition, Time series analysis},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\kiera\\Zotero\\storage\\PS7YL2EV\\8321795.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\kiera\\Zotero\\storage\\MWXBK6ZM\\Maghilnan and Kumar - 2017 - Sentiment analysis on speaker specific speech data.pdf:application/pdf},
}

@misc{noauthor_mutagen_2023,
	title = {Mutagen},
	copyright = {GPL-3.0},
	url = {https://github.com/Mutagen-Modding/Mutagen},
	abstract = {A .NET library for analyzing, creating, and manipulating Bethesda mods},
	urldate = {2023-04-03},
	publisher = {Mutagen-Modding},
	month = mar,
	year = {2023},
	note = {original-date: 2017-07-14T01:58:38Z},
}

@article{murugaiyan_aspect-based_2023,
	title = {Aspect-{Based} {Sentiment} {Analysis} of {Customer} {Speech} {Data} {Using} {Deep} {Convolutional} {Neural} {Network} and {BiLSTM}},
	issn = {1866-9964},
	url = {https://doi.org/10.1007/s12559-023-10127-6},
	doi = {10.1007/s12559-023-10127-6},
	abstract = {The process of detecting sentiments of particular context from human speech emotions is naturally in-built for humans unlike computers, where it is not possible to process human emotions by a machine for predicting sentiments of a particular context. Though machines can easily understand the content-based information, accessing the real emotion behind it is difficult. Aspect-based sentiment analysis based on speech emotion recognition framework can bridge the gap between these problems. The proposed model helps people with autism spectrum disorder (ASD) to understand other’s sentiments expressed through speech data about the recently purchased product based on various aspects of the product. It is a framework through which different sound discourse documents are characterized into various feelings like happy, sad, anger, and neutral and label the sound with aspect-wise sentiment polarity. This study proposed a hybrid model using deep convolutional neural networks (DCNN) for speech emotion recognition, bidirectional long short term memory (BiLSTM) for speech aspect recognition, and rule-based classifier for aspect-wise sentiment classification. In the existing work, sentiment analysis was carried out on speech data, but aspect-based sentiment analysis on speech data was not carried out successfully. The proposed model extracted standard Mel frequency cepstral coefficient (MFCC) features from customer speech data about product review and generated aspect-wise sentiment label. Enhanced cat swarm optimization (ECSO) algorithm was used for selection features from the extracted feature in the proposed model that improved the overall sentiment classification accuracy. The proposed hybrid framework obtained promising results on sentiment classification accuracy of 93.28\%, 91.45\%, 92.12\%, and 90.45\% on four benchmark datasets. The proposed hybrid framework sentiment classification accuracy on these benchmark datasets were compared with other CNN variants and shown better performance. Sentiment classification accuracy of the proposed model with state-of-art methods on the four benchmark datasets was compared and shown better performance. Aspect classification accuracy of the proposed with state-of-art methods on the benchmark datasets was compared and shown better performance. The developed hybrid model using DCNN, BiLSTM, and rule-based classifier outperformed the state-of-art models for aspect-based sentiment analysis by incorporating ECSO algorithm in feature selection process. The proposed model will help to perform aspect-based sentiment analysis on all domains with specified aspect corpus.},
	language = {en},
	urldate = {2023-04-14},
	journal = {Cognitive Computation},
	author = {Murugaiyan, Sivakumar and Uyyala, Srinivasulu Reddy},
	month = mar,
	year = {2023},
	keywords = {Aspect based sentiment analysis, Convolutional neural network, Customer speech review, Deep learning, Machine learning, Speech emotion recognition},
	file = {Full Text PDF:C\:\\Users\\kiera\\Zotero\\storage\\3Y3AY86D\\Murugaiyan and Uyyala - 2023 - Aspect-Based Sentiment Analysis of Customer Speech.pdf:application/pdf},
}

@article{bhaskar_hybrid_2015,
	series = {Proceedings of the {International} {Conference} on {Information} and {Communication} {Technologies}, {ICICT} 2014, 3-5 {December} 2014 at {Bolgatty} {Palace} \& {Island} {Resort}, {Kochi}, {India}},
	title = {Hybrid {Approach} for {Emotion} {Classification} of {Audio} {Conversation} {Based} on {Text} and {Speech} {Mining}},
	volume = {46},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050915001763},
	doi = {10.1016/j.procs.2015.02.112},
	abstract = {One of the greatest challenges in speech technology is estimating the speaker's emotion. Most of the existing approaches concentrate either on audio or text features. In this work, we propose a novel approach for emotion classification of audio conversation based on both speech and text. The novelty in this approach is in the choice of features and the generation of a single feature vector for classification. Our main intention is to increase the accuracy of emotion classification of speech by considering both audio and text features. In this work we use standard methods such as Natural Language Processing, Support Vector Machines, WordNet Affect and SentiWordNet. The dataset for this work have been taken from Semval -2007 and eNTERFACE’05 EMOTION Database.},
	language = {en},
	urldate = {2023-04-17},
	journal = {Procedia Computer Science},
	author = {Bhaskar, Jasmine and Sruthi, K. and Nedungadi, Prema},
	month = jan,
	year = {2015},
	keywords = {Emotion classification, hybrid approach, speech mining, text mining},
	pages = {635--643},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\kiera\\Zotero\\storage\\EJP5QRCZ\\Bhaskar et al. - 2015 - Hybrid Approach for Emotion Classification of Audi.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\kiera\\Zotero\\storage\\BG8KFV7Q\\S1877050915001763.html:text/html},
}
